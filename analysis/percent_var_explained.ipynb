{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to analyze the fMRI BOLD variance explained by physiological signals and compare between age groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load all of the necessary inports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy.io import loadmat, savemat\n",
    "from scipy.linalg import pinv\n",
    "from scipy.signal import correlate, detrend, convolve\n",
    "from scipy.interpolate import interp1d\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next chunk of code will create the physiological basis set. To do this, we will create a function that convolves the physiological basis functions (CRF, RRF, HRF) with their respective physiological measure (HR, RV, CO2). (Figure 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 2.4 # HRV-ER dataset has TR of 2.4 s, NKI uses 1.4 s TR \n",
    "t = np.arange(0, 40 + dt, dt)  # assume 40-s long total for each basis set \n",
    "\n",
    "# CRF basis\n",
    "crf_p = 0.3 * t**2.7 * np.exp(-t / 1.6) - 1.05 * np.exp(-((t - 12)**2) / 18) # primary (Chang et al., 2009)\n",
    "crf_t1 = 1.94 * t**1.7 * np.exp(-t / 1.6) - 0.45 * t**2.7 * np.exp(-t / 1.6) # time derivative 1 (Chen et al., 2020)\n",
    "crf_t2 = 0.55 * (t - 12) * np.exp(-((t - 12)**2) / 18) # time derivative 2 (Chen et al., 2020)\n",
    "crf_d1 = 0.056 * t**3.7 * np.exp(-t / 1.6) # dispersion 1 (Chen et al., 2020)\n",
    "crf_d2 = 0.15 * (t - 12)**2 * np.exp(-((t - 12)**2) / 18) # dispersion 2 (Chen et al., 2020)\n",
    "\n",
    "# RRF basis\n",
    "rrf_p = 0.6 * t**2.1 * np.exp(-t / 1.6) - 0.0023 * t**3.54 * np.exp(-t / 4.25) # primary (Birn et al., 2008)\n",
    "rrf_t1 = -0.79 * t**2.1 * np.exp(-t / 1.6) + 2.66 * t**1.1 * np.exp(-t / 1.6) # time derivative 1 (Chen et al., 2020)\n",
    "rrf_t2 = -0.069 * t**2.54 * np.exp(-t / 4.25) + 0.0046 * t**3.54 * np.exp(-t / 4.25) # time derivative 2 (Chen et al., 2020)\n",
    "rrf_d1 = 0.16 * t**3.1 * np.exp(-t / 1.6) # dispersion 1 (Chen et al., 2020)\n",
    "rrf_d2 = 0.00014 * t**4.54 * np.exp(-t / 4.25) # dispersion 2 (Chen et al., 2020)\n",
    "\n",
    "# HRF basis\n",
    "hrf = loadmat(\"/path/to/hrf.mat\")['hrf_bf'] # load HRF basis functions (the version I used has 2.1 s TR)\n",
    "hrf_p = hrf[:, 0] # HRF primary (6 second peak)\n",
    "hrf_t = hrf[:, 1] # HRF time derivative\n",
    "hrf_d = hrf[:, 2] # HRF dispersion \n",
    "\n",
    "# Resample HRF basis to 2.4 s TR from 2.1 s TR\n",
    "n = len(hrf_p)\n",
    "original_t = np.arange(0, n * 2.1, 2.1)\n",
    "new_t = np.arange(0, original_t[-1] + dt, dt)\n",
    "\n",
    "hrf_p= interp1d(original_t, hrf_p, kind='linear', fill_value='extrapolate')(new_t)\n",
    "hrf_t = interp1d(original_t, hrf_t, kind='linear', fill_value='extrapolate')(new_t)\n",
    "hrf_d = interp1d(original_t, hrf_d, kind='linear', fill_value='extrapolate')(new_t)\n",
    "\n",
    "def create_physio_basis_HRV_ER(etco2, hr, rv):\n",
    "    \"\"\"\n",
    "    Create a physiological basis set for HRV and ER analysis by convolving \n",
    "    input physiological signals (etco2, heart rate, respiratory variation) \n",
    "    with their respective basis functions.\n",
    "\n",
    "    This function generates a design matrix for modeling physiological effects \n",
    "    in fMRI data, specifically focusing on HRV (Heart Rate Variability) and \n",
    "    ER (End-tidal CO2 Responses). It uses convolution with predefined basis \n",
    "    functions for HRF (Hemodynamic Response Function), CRF (Cardiac Response \n",
    "    Function), and RRF (Respiratory Response Function).\n",
    "\n",
    "    Parameters:\n",
    "        etco2 (np.ndarray): End-tidal CO2 signal, a 1D array.\n",
    "        hr (np.ndarray): Heart rate signal, a 1D array.\n",
    "        rv (np.ndarray): Respiratory variation signal, a 1D array.\n",
    "\n",
    "    Global Variables:\n",
    "        hrf_p, hrf_t, hrf_d: HRF basis functions for CO2.\n",
    "        crf_p, crf_t1, crf_t2, crf_d1, crf_d2: CRF basis functions for heart rate.\n",
    "        rrf_p, rrf_t1, rrf_t2, rrf_d1, rrf_d2: RRF basis functions for respiratory variation.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A concatenated design matrix `X_physio`, with the following structure:\n",
    "            - Column 1: Raw etco2 signal.\n",
    "            - Columns 2-4: HRF convolved with etco2.\n",
    "            - Columns 5-9: CRF convolved with heart rate.\n",
    "            - Columns 10-14: RRF convolved with respiratory variation.\n",
    "    \"\"\"\n",
    "    global crf_p, crf_t1, crf_t2, crf_d1, crf_d2, rrf_p, rrf_t1, rrf_t2, rrf_d1, rrf_d2, hrf_p, hrf_t, hrf_d\n",
    "\n",
    "    # Convolve etco2 with HRF basis\n",
    "    CO2 = etco2\n",
    "    CO2 = CO2.flatten()  # Ensure column vector\n",
    "\n",
    "    CO2_conv = np.zeros((len(CO2), 3))\n",
    "    CO2_conv[:, 0] = convolve(CO2, hrf_p, mode='full')[:len(CO2)]\n",
    "    CO2_conv[:, 1] = convolve(CO2, hrf_t, mode='full')[:len(CO2)]\n",
    "    CO2_conv[:, 2] = convolve(CO2, hrf_d, mode='full')[:len(CO2)]\n",
    "    CO2_basis_regs = CO2_conv\n",
    "\n",
    "    # Convolve HR with CRF basis\n",
    "    HR = hr \n",
    "    HR = HR.flatten()  # Ensure column vector\n",
    "\n",
    "    HR_conv = np.zeros((len(HR), 5))\n",
    "    HR_conv[:, 0] = convolve(HR, crf_p, mode='full')[:len(HR)]\n",
    "    HR_conv[:, 1] = convolve(HR, crf_t1, mode='full')[:len(HR)]\n",
    "    HR_conv[:, 2] = convolve(HR, crf_t2, mode='full')[:len(HR)]\n",
    "    HR_conv[:, 3] = convolve(HR, crf_d1, mode='full')[:len(HR)]\n",
    "    HR_conv[:, 4] = convolve(HR, crf_d2, mode='full')[:len(HR)]\n",
    "    HR_basis_regs = HR_conv\n",
    "\n",
    "    # Convolve RV with RRF basis\n",
    "    RV = rv\n",
    "    RV = RV.flatten()  # Ensure column vector\n",
    "\n",
    "    RV_conv = np.zeros((len(RV), 5))\n",
    "    RV_conv[:, 0] = convolve(RV, rrf_p, mode='full')[:len(RV)]\n",
    "    RV_conv[:, 1] = convolve(RV, rrf_t1, mode='full')[:len(RV)]\n",
    "    RV_conv[:, 2] = convolve(RV, rrf_t2, mode='full')[:len(RV)]\n",
    "    RV_conv[:, 3] = convolve(RV, rrf_d1, mode='full')[:len(RV)]\n",
    "    RV_conv[:, 4] = convolve(RV, rrf_d2, mode='full')[:len(RV)]\n",
    "    RV_basis_regs = RV_conv\n",
    "\n",
    "    # Concatenate etco2, CO2, HR, and RV basis functions\n",
    "    X_physio = np.hstack([CO2.reshape(-1, 1), CO2_basis_regs, HR_basis_regs, RV_basis_regs])\n",
    "\n",
    "    return X_physio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few handy utility functions (e.g. loading nii files and participant csv files into dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii(file_path):\n",
    "    \"\"\"\n",
    "    Load a NIfTI file and return the image data as a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the NIfTI file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The image data contained in the NIfTI file.\n",
    "        np.ndarray: The affine transformation matrix from the NIfTI file.\n",
    "    \"\"\"\n",
    "    temp = nib.load(file_path)\n",
    "    return temp.get_fdata(), temp.affine\n",
    "\n",
    "def load_pre(): \n",
    "    \"\"\"\n",
    "    Load and return the pre-session dataset.\n",
    "\n",
    "    This function reads a CSV file containing information about subjects\n",
    "    during a pre-session experiment, including age and gender.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the pre-session data.\n",
    "    \"\"\"\n",
    "    infile_pre = \"/data1/neurdylab/songrw/derivates/hrv_er/ses_pre_age_gender.csv\"\n",
    "    df_pre = pd.read_csv(infile_pre)\n",
    "    return df_pre\n",
    "\n",
    "def load_post():\n",
    "    \"\"\"\n",
    "    Load and return the post-session dataset.\n",
    "\n",
    "    This function reads a CSV file containing information about subjects\n",
    "    during a post-session experiment, including age and gender.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the post-session data.\n",
    "    \"\"\"\n",
    "    infile_post = \"/data1/neurdylab/songrw/derivates/hrv_er/ses_post_age_gender.csv\"\n",
    "    df_post = pd.read_csv(infile_post)\n",
    "    return df_post\n",
    "\n",
    "def load_shared():\n",
    "    \"\"\"\n",
    "    Load and return a subset of the pre-session dataset containing only\n",
    "    subjects who participated in both the pre- and post-session experiments.\n",
    "\n",
    "    This function identifies the common subject IDs between the pre-session\n",
    "    and post-session datasets, and filters the pre-session dataset to include\n",
    "    only these shared subjects.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing data for shared subjects in the pre-session dataset.\n",
    "    \"\"\"\n",
    "    # Load the pre-session data and extract subject IDs\n",
    "    infile_pre = \"/data1/neurdylab/songrw/derivates/hrv_er/ses_pre_age_gender.csv\"\n",
    "    df_pre = pd.read_csv(infile_pre)\n",
    "    sub_pre = df_pre['subs_id'].values\n",
    "\n",
    "    # Load the post-session data and extract subject IDs\n",
    "    infile_post = \"/data1/neurdylab/songrw/derivates/hrv_er/ses_post_age_gender.csv\"\n",
    "    df_post = pd.read_csv(infile_post)\n",
    "    sub_post = df_post['subs_id'].values\n",
    "\n",
    "    # Find the intersection of subject IDs between the two datasets\n",
    "    shared_subs = np.intersect1d(sub_pre, sub_post)\n",
    "\n",
    "    # Filter the pre-session dataset to include only the shared subjects\n",
    "    df_shared = df_pre[df_pre['subs_id'].isin(shared_subs)]\n",
    "    return df_shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the percent variance in BOLD explained by physiological signals for a given subject on a voxel-by-voxel basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_percent_variance_explained(name, session, mask_indices): \n",
    "    \"\"\"\n",
    "    Calculate the percent variance in fMRI data explained by various physiological signals.\n",
    "\n",
    "    This function uses physiological signals (heart rate, end-tidal CO2, and respiratory variation)\n",
    "    as regressors to estimate the variance they explain in fMRI voxel time series, \n",
    "    based on a mask of brain regions of interest. \n",
    "\n",
    "    The percent variance explained is calculated for:\n",
    "    - Heart rate and CO2 combined\n",
    "    - Heart rate only\n",
    "    - CO2 only\n",
    "    - Respiratory variation (RV) only\n",
    "    - Heart rate and respiratory variation combined\n",
    "\n",
    "    Parameters:\n",
    "        name (str): Subject's name or identifier.\n",
    "        session (str): Session identifier (e.g., \"pre\", \"post\").\n",
    "        mask_indices (np.ndarray): Indices of voxels within the brain mask (based on an MNI template).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contains the percent variance explained for different regressors:\n",
    "            - percent_variance_hrco2 (np.ndarray): Variance explained by heart rate and CO2 combined (voxels x 1).\n",
    "            - percent_variance_hr (np.ndarray): Variance explained by heart rate only (voxels x 1).\n",
    "            - percent_variance_co2 (np.ndarray): Variance explained by CO2 only (voxels x 1).\n",
    "            - percent_variance_rv (np.ndarray): Variance explained by RV only (voxels x 1).\n",
    "            - percent_variance_hrrv (np.ndarray): Variance explained by heart rate and RV combined (voxels x 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    physio_mat = loadmat(f'/path/to/preprocessed/physio/mat/file/for/session/and/subject.mat')\n",
    "    nii_path = '/path/to/func/nii/file/for/session/and/subject.nii.gz'\n",
    "\n",
    "    nn, _ = load_nii(nii_path)\n",
    "    hr = physio_mat['REGS']['hr'][0][0].flatten()\n",
    "    co2 = physio_mat['RESP']['etco2'][0][0].flatten() # For HRV-ER\n",
    "    rv = physio_mat['REGS']['rv'][0][0].flatten()\n",
    "\n",
    "    # Detrend physiological signals to remove linear trends\n",
    "    co2 = detrend(co2)\n",
    "    hr = detrend(hr)\n",
    "    rv = detrend(rv)\n",
    "\n",
    "    dims = nn.shape\n",
    "    V = nn.reshape(-1, dims[3]) # Reshape to 2D matrix (voxels x time)\n",
    "    Y = V.T  # Transpose into (time x voxels) matrix\n",
    "\n",
    "    # Normalize each column (voxel) to reflect percent signal change\n",
    "    for k in range(Y.shape[1]):\n",
    "        avg = np.mean(Y[:, k])\n",
    "        if avg != 0:\n",
    "            Y[:, k] = (Y[:, k] - avg) / avg\n",
    "\n",
    "    Y_clean = Y.T # (voxel x time)\n",
    "    Y_clean = Y_clean[mask_indices, :] # mask the brain regions inside the mask (MNI template)\n",
    "\n",
    "    X = create_physio_basis_HRV_ER(co2, hr, rv, 2.4) # X is the design matrix for physiological regressors  \n",
    "\n",
    "    # CO2 and HR\n",
    "    X1 = np.hstack([np.ones((X.shape[0], 1)), X[:, 1:9]])\n",
    "    B1 = pinv(X1) @ Y_clean.T  # Least-squares regression coefficients\n",
    "    percent_variance_hrco2 = np.var((X1 @ B1).T, axis=1, keepdims=True) / np.var(Y_clean, axis=1, keepdims=True) # voxels x 1\n",
    "\n",
    "    # HR only\n",
    "    X2 = np.hstack([np.ones((X.shape[0], 1)), X[:, 4:9]])\n",
    "    B2 = pinv(X2) @ Y_clean.T  # Least-squares regression coefficients\n",
    "    percent_variance_hr = np.var((X2 @ B2).T, axis=1, keepdims=True) / np.var(Y_clean, axis=1, keepdims=True)\n",
    "\n",
    "    # CO2 only\n",
    "    X3 = np.hstack([np.ones((X.shape[0], 1)), X[:, 1:4]])\n",
    "    B3 = pinv(X3) @ Y_clean.T  # Least-squares regression coefficients\n",
    "    percent_variance_co2 = np.var((X3 @ B3).T, axis=1, keepdims=True) / np.var(Y_clean, axis=1, keepdims=True)\n",
    "\n",
    "    # RV only\n",
    "    X4 = np.hstack([np.ones((X.shape[0], 1)), X[:, 9:]])\n",
    "    B4 = pinv(X4) @ Y_clean.T  # Least-squares regression coefficients\n",
    "    percent_variance_rv = np.var((X4 @ B4).T, axis=1, keepdims=True) / np.var(Y_clean, axis=1, keepdims=True)\n",
    "\n",
    "    # HRRV only\n",
    "    X5 = np.hstack([np.ones((X.shape[0], 1)), X[:, 4:]])\n",
    "    B5 = pinv(X5) @ Y_clean.T  # Least-squares regression coefficients\n",
    "    percent_variance_hrrv = np.var((X5 @ B5).T, axis=1, keepdims=True) / np.var(Y_clean, axis=1, keepdims=True)\n",
    "\n",
    "    return percent_variance_hrco2, percent_variance_hr, percent_variance_co2, percent_variance_rv, percent_variance_hrrv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare percent variance of BOLD explained by physiological signals between young and old. To do this, we will run calc_percent_variance_explained() for every subject, and reshape the returned \"physiological maps\" into 91x109x91 matrices (the size of one 3D 2mm x 2mm x 2mm nii volume.) We will then concatenate all of the subjects 3D nii volume to obtain 1 4D volume (which is the format the FSL randomise prefers) of size 91 x 109 x 91 x # of participants. Create design and contrast matrices based on the order of the participants concatenated to form the 4D volume. (Figure 3)\n",
    "\n",
    "Source: https://web.mit.edu/fsl_v5.0.10/fsl/doc/wiki/Randomise(2f)UserGuide.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data for a single participant\n",
    "def process_participant(i, subs_id, mask_indices):\n",
    "    \"\"\"\n",
    "    Process data for a single participant.\n",
    "\n",
    "    Parameters:\n",
    "        i (int): Participant index.\n",
    "        subs_id (list): List of subject IDs.\n",
    "        mask_indices (np.ndarray): Indices of voxels within the brain mask.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Participant index and arrays for percent variance explained \n",
    "               (HR, CO2, RV, HRRV, HR+CO2).\n",
    "    \"\"\"\n",
    "    hrco2, hr, co2, rv, hrrv = calc_percent_variance_explained(subs_id[i], \"pre\", mask_indices)\n",
    "    return i, hrco2, co2, rv, hrrv, hr\n",
    "\n",
    "# Function to create a design matrix\n",
    "def create_design_matrix(df):\n",
    "    \"\"\"\n",
    "    Create a design matrix for group comparison (young vs. old).\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing participant information, including age.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Design matrix with one column for \"young\" and another for \"old\".\n",
    "    \"\"\"\n",
    "    young = np.array(df['age'] < 50, dtype=int)\n",
    "    old = np.array(df['age'] >= 50, dtype=int)\n",
    "    return np.concatenate((young[:, np.newaxis], old[:, np.newaxis]), axis=1)\n",
    "\n",
    "# Function to create a contrast matrix\n",
    "def create_contrast_matrix():\n",
    "    \"\"\"\n",
    "    Create a contrast matrix for group comparison (young vs. old).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Contrast matrix for statistical analysis.\n",
    "    \"\"\"\n",
    "    return np.array([[1, -1], [-1, 1]])\n",
    "\n",
    "def update_brain_map(data_update, mask_indices):\n",
    "    \"\"\"\n",
    "    Map flattened data back into brain space.\n",
    "\n",
    "    Parameters:\n",
    "        data_update (np.ndarray): Flattened data.\n",
    "        mask_indices (np.ndarray): Indices of brain mask voxels.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Reshaped data in brain space (91 x 109 x 91).\n",
    "    \"\"\"\n",
    "    brain_map = np.zeros((91 * 109 * 91, 1))\n",
    "    brain_map[mask_indices] = data_update\n",
    "    return brain_map.reshape(91, 109, 91)\n",
    "\n",
    "def save_nifti(data, affine, file_path):\n",
    "    \"\"\"\n",
    "    Save data as a NIfTI file.\n",
    "\n",
    "    Parameters:\n",
    "        data (np.ndarray): Data to be saved.\n",
    "        affine (np.ndarray): Affine transformation matrix.\n",
    "        file_path (str): File path for saving the NIfTI file.\n",
    "    \"\"\"\n",
    "    nii = nib.Nifti1Image(data, affine)\n",
    "    nib.save(nii, file_path)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform the whole-brain analysis.\n",
    "    - Loads demographic and brain mask data.\n",
    "    - Initializes arrays for storing variance explained results.\n",
    "    - Processes each participant's data in parallel.\n",
    "    - Saves variance explained results as NIfTI files.\n",
    "    - Generates and saves design and contrast matrices for further analysis.\n",
    "    \"\"\"\n",
    "    # Load demographic data and brain mask\n",
    "    df_pre = load_pre()\n",
    "    subs = df_pre['subs_id'].values\n",
    "    N = len(subs)\n",
    "\n",
    "    mask, affine = load_nii(\"/path/to/MNI152_T1_2mm_brain.nii\")\n",
    "    mask = mask.astype(bool)\n",
    "    mask_indices = np.where(mask.flatten())[0]\n",
    "\n",
    "    # Initialize result arrays\n",
    "    hr_cov = np.zeros((91, 109, 91, N))\n",
    "    rv_cov = np.zeros((91, 109, 91, N))\n",
    "    co2_cov = np.zeros((91, 109, 91, N))\n",
    "    hrco2_cov = np.zeros((91, 109, 91, N))\n",
    "    hrrv_cov = np.zeros((91, 109, 91, N))\n",
    "\n",
    "    # Parallel processing of participants\n",
    "    num_cores = 16\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "        try: \n",
    "            futures = [executor.submit(process_participant, i, subs, mask_indices) for i in range(N)]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                index, hr_cov_update, co2_cov_update, rv_cov_update, hrrv_cov_update, hrco2_cov_update = future.result()\n",
    "\n",
    "                # Reshape results back into brain space\n",
    "                hr_cov[:, :, :, index] = update_brain_map(hr_cov_update, mask_indices)\n",
    "                co2_cov[:, :, :, index] = update_brain_map(co2_cov_update, mask_indices)\n",
    "                rv_cov[:, :, :, index] = update_brain_map(rv_cov_update, mask_indices)\n",
    "                hrrv_cov[:, :, :, index] = update_brain_map(hrrv_cov_update, mask_indices)\n",
    "                hrco2_cov[:, :, :, index] = update_brain_map(hrco2_cov_update, mask_indices)\n",
    "\n",
    "                print(f\"Processing complete for participant {subs[index]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    output_dir = '/path/to/output/directory/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save variance explained results as NIfTI files\n",
    "    save_nifti(hr_cov, affine, os.path.join(output_dir, 'hr_cov_young_old.nii.gz'))\n",
    "    save_nifti(co2_cov, affine, os.path.join(output_dir, 'co2_cov_young_old.nii.gz'))\n",
    "    save_nifti(rv_cov, affine, os.path.join(output_dir, 'rv_cov_young_old.nii.gz'))\n",
    "    save_nifti(hrrv_cov, affine, os.path.join(output_dir, 'hrrv_cov_young_old.nii.gz'))\n",
    "    save_nifti(hrco2_cov, affine, os.path.join(output_dir, 'hrco2_cov_young_old.nii.gz'))\n",
    "\n",
    "    # Generate and save design and contrast matrices\n",
    "    design = create_design_matrix(df_pre)\n",
    "    np.savetxt(os.path.join(output_dir, 'design_matrix.txt'), design, fmt='%d')\n",
    "\n",
    "    contrast = create_contrast_matrix()\n",
    "    np.savetxt(os.path.join(output_dir, 'contrast_matrix.txt'), contrast, fmt='%d')\n",
    "\n",
    "    os.system('bash /path/to/randomise_young_old_baseline.sh') # Run randomise script for group comparison\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare post - pre difference in percent variance in BOLD explained between young and old adults for both Osc+ and Osc- conditions. This will give us a total of 2 4D matrices: one for all participants in Osc+ and another for everyone in Osc-. Run whole brain stats using fsl randomise (Figure 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_participant_session(name, session, mask_indices):\n",
    "    \"\"\"\n",
    "    Processes a single participant's data for a given session (pre or post) \n",
    "    and calculates the variance explained by different physiological components.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): Participant identifier.\n",
    "        session (str): Session identifier ('pre' or 'post').\n",
    "        mask_indices (np.ndarray): Indices of voxels in the brain mask.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with variance explained for each physiological metric:\n",
    "            - 'hr': Heart rate\n",
    "            - 'co2': End-tidal CO2\n",
    "            - 'rv': Respiratory variation\n",
    "            - 'hrco2': Combined heart rate and CO2\n",
    "            - 'hrrv': Combined heart rate and respiratory variation\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    hrco2, hr, co2, rv, hrrv = calc_percent_variance_explained(name, session, mask_indices)\n",
    "    results['hr'] = hr\n",
    "    results['co2'] = co2\n",
    "    results['rv'] = rv\n",
    "    results['hrco2'] = hrco2\n",
    "    results['hrrv'] = hrrv\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_participant(name, mask_indices):\n",
    "    \"\"\"\n",
    "    Processes both pre and post sessions for a participant, calculates the \n",
    "    post-pre differences in variance explained for various physiological components.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): Participant identifier.\n",
    "        mask_indices (np.ndarray): Indices of voxels in the brain mask.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - name (str): Participant identifier.\n",
    "            - diff_results (dict): Dictionary with post-pre differences for each metric:\n",
    "                - 'hr', 'co2', 'rv', 'hrco2', 'hrrv'.\n",
    "\n",
    "    Exceptions:\n",
    "        If an error occurs, prints an error message and returns None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pre_results = process_participant_session(name, 'pre', mask_indices)\n",
    "        post_results = process_participant_session(name, 'post', mask_indices)\n",
    "        \n",
    "        # Calculate post-pre difference\n",
    "        diff_results = {metric: post_results[metric] - pre_results[metric] \n",
    "                       for metric in pre_results.keys()}\n",
    "        return name, diff_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subject {name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform whole-brain analysis for young vs. old OSC+ and OSC- \n",
    "    groups (pre vs post comparison). The analysis includes the following steps:\n",
    "\n",
    "    1. Load demographic data for shared participants across pre and post sessions.\n",
    "    2. Divide participants into groups based on age and OSC+ or OSC- categorization.\n",
    "    3. Process participant data for all groups in parallel, calculating post-pre differences.\n",
    "    4. Save variance explained results for each group comparison as NIfTI files.\n",
    "    5. Generate design matrices for statistical analysis.\n",
    "\n",
    "    Workflow:\n",
    "        - Young OSC+ vs Old OSC+ comparison\n",
    "        - Young OSC- vs Old OSC- comparison\n",
    "\n",
    "    Output:\n",
    "        - NIfTI files for variance explained results for each group.\n",
    "        - Design matrices for statistical analysis.\n",
    "        - Contrast matrix for group comparison.\n",
    "    \"\"\"\n",
    "    metrics = ['hr', 'co2', 'rv', 'hrrv', 'hrco2']\n",
    "\n",
    "    df_shared = load_shared()\n",
    "    young_shared = df_shared[df_shared['age'] < 50]['subs_id'].values\n",
    "    old_shared = df_shared[df_shared['age'] >= 50]['subs_id'].values\n",
    "\n",
    "    young_osc_plus = sorted([subj for subj in young_shared if subj[4] == '5'])\n",
    "    young_osc_minus = sorted([subj for subj in young_shared if subj[4] == '6'])\n",
    "    old_osc_plus = sorted([subj for subj in old_shared if subj[4] == '7'])\n",
    "    old_osc_minus = sorted([subj for subj in old_shared if subj[4] == '8'])\n",
    "\n",
    "    print(f\"Young OSC+ subjects: {len(young_osc_plus)}\")\n",
    "    print(f\"Young OSC- subjects: {len(young_osc_minus)}\")\n",
    "    print(f\"Old OSC+ subjects: {len(old_osc_plus)}\")\n",
    "    print(f\"Old OSC- subjects: {len(old_osc_minus)}\")\n",
    "\n",
    "    # Load brain mask\n",
    "    mask, affine = load_nii(\"/path/to/MNI152_T1_2mm_brain.nii\")\n",
    "    mask = mask.astype(bool)\n",
    "    mask_indices = np.where(mask.flatten())[0]\n",
    "    shape = (91, 109, 91)\n",
    "    \n",
    "    # Initialize results arrays for all groups\n",
    "    young_osc_plus_results = {metric: np.zeros(shape + (len(young_osc_plus),)) for metric in metrics}\n",
    "    young_osc_minus_results = {metric: np.zeros(shape + (len(young_osc_minus),)) for metric in metrics}\n",
    "    old_osc_plus_results = {metric: np.zeros(shape + (len(old_osc_plus),)) for metric in metrics}\n",
    "    old_osc_minus_results = {metric: np.zeros(shape + (len(old_osc_minus),)) for metric in metrics}\n",
    "\n",
    "    # Process all subjects using parallel processing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=16) as executor:\n",
    "        # Process all groups\n",
    "        for group_name, subjects, results_dict in [\n",
    "            (\"Young OSC+\", young_osc_plus, young_osc_plus_results),\n",
    "            (\"Young OSC-\", young_osc_minus, young_osc_minus_results),\n",
    "            (\"Old OSC+\", old_osc_plus, old_osc_plus_results),\n",
    "            (\"Old OSC-\", old_osc_minus, old_osc_minus_results)\n",
    "        ]:\n",
    "            print(f\"Processing {group_name} subjects...\")\n",
    "            futures = []\n",
    "            for i, subj in enumerate(subjects):\n",
    "                futures.append((executor.submit(process_participant, subj, mask_indices), i))\n",
    "                \n",
    "            for future, idx in futures:\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result is not None:\n",
    "                        subj, diff_results = result\n",
    "                        for metric in metrics:\n",
    "                            metric_zeros = np.zeros((91*109*91, 1))\n",
    "                            metric_zeros[mask_indices] = diff_results[metric]\n",
    "                            metric_reshaped = metric_zeros.reshape(91, 109, 91)\n",
    "                            results_dict[metric][:,:,:,idx] = metric_reshaped\n",
    "                        print(f\"Completed {group_name} subject {subj}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {group_name} subject: {e}\")\n",
    "\n",
    "    # Create output directories\n",
    "    output_dir = '/path/to/output/directory/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save maps for Young OSC+ vs Old OSC+ comparison\n",
    "    for metric in metrics:\n",
    "        combined_maps = np.concatenate([\n",
    "            young_osc_plus_results[metric],\n",
    "            old_osc_plus_results[metric]\n",
    "        ], axis=3)\n",
    "        \n",
    "        output_path = os.path.join(output_dir, f'{metric}_young_vs_old_osc_plus.nii.gz')\n",
    "        nii = nib.Nifti1Image(combined_maps, affine)\n",
    "        nib.save(nii, output_path)\n",
    "        \n",
    "    # Create corresponding design matrix for Young OSC+ vs Old OSC+ comparison\n",
    "    design = np.zeros((len(young_osc_plus) + len(old_osc_plus), 2))\n",
    "    design[:len(young_osc_plus), 0] = 1  # Young OSC+\n",
    "    design[len(young_osc_plus):, 1] = 1  # Old OSC+\n",
    "    np.savetxt(os.path.join(output_dir, f'young_vs_old_osc_plus_design.txt'), design, fmt='%d')\n",
    "\n",
    "    # Save maps for Young OSC- vs Old OSC- comparison\n",
    "    for metric in metrics:\n",
    "        combined_maps = np.concatenate([\n",
    "            young_osc_minus_results[metric],\n",
    "            old_osc_minus_results[metric]\n",
    "        ], axis=3)\n",
    "        \n",
    "        output_path = os.path.join(output_dir, f'{metric}_young_vs_old_osc_minus.nii.gz')\n",
    "        nii = nib.Nifti1Image(combined_maps, affine)\n",
    "        nib.save(nii, output_path)\n",
    "        \n",
    "    # Create corresponding design matrix for Young OSC- vs Old OSC- comparison\n",
    "    design = np.zeros((len(young_osc_minus) + len(old_osc_minus), 2))\n",
    "    design[:len(young_osc_minus), 0] = 1  # Young OSC-\n",
    "    design[len(young_osc_minus):, 1] = 1  # Old OSC-\n",
    "    np.savetxt(os.path.join(output_dir, f'young_vs_old_osc_minus_design.txt'), design, fmt='%d')\n",
    "\n",
    "    contrast = create_contrast_matrix() # Common contrast matrix for both comparisons \n",
    "    np.savetxt(os.path.join(output_dir, 'contrast_matrix.txt'), contrast, fmt='%d')\n",
    "\n",
    "    os.system('bash /path/to/randomise_young_old_osc_post-pre.sh') # Run randomise script for group comparison\n",
    "    print(\"Analysis complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
